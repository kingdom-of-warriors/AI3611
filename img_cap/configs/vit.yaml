model: vit
outputpath: experiments/vit

dataset_base_path: data
vocab_path: utils/vocab_set.pkl
image_len: 224
embedding_dim: 300
attention_dim: 256
decoder_size: 256
sample_method: greed # 'greed' or 'beam'
train_args:
    batch_size: 128
    learning_rate: !!float 1e-3
    num_epochs: 45
    save_freq: 10
eval_args:
    batch_size: 1

